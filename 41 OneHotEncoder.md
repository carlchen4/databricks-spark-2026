## ä¸€ã€Pipeline æ˜¯ä»€ä¹ˆï¼Ÿ

åœ¨ Spark ML ä¸­ï¼Œ**Pipeline å°±åƒæµæ°´çº¿**ï¼ŒæŠŠå¤šä¸ª **æ•°æ®å¤„ç†æ­¥éª¤ + ç‰¹å¾å·¥ç¨‹ + æ¨¡å‹** ä¸²èµ·æ¥ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œã€‚

https://www.youtube.com/watch?v=rsyrZnZ8J2o

https://www.youtube.com/watch?v=G2iVj7WKDFk

### ä½œç”¨ï¼š

1. **æŠŠæ•´ä¸ªæµç¨‹è‡ªåŠ¨åŒ–**

   * ä¸ç”¨æ‰‹åŠ¨ä¸€ä¸ªä¸ª `transform()`
   * è®­ç»ƒ / æµ‹è¯• / ç”Ÿäº§ç”¨åŒä¸€ä¸ªæµç¨‹
2. **é˜²æ­¢æ•°æ®æ³„æ¼**

   * æ¯”å¦‚ StringIndexer åªç”¨è®­ç»ƒé›† fitï¼Œä¸ä¼šçœ‹åˆ°æµ‹è¯•é›†æ–°ç±»åˆ«
3. **æ˜“ç»´æŠ¤ã€æ˜“å¤ç”¨**

   * é“¶è¡Œä¸šåŠ¡å¤æ‚ï¼ŒPipeline å¯åŠ å¤šä¸ªæ­¥éª¤ï¼šç¼–ç ã€å¡«å……ç¼ºå¤±å€¼ã€å½’ä¸€åŒ–ã€æ»šåŠ¨ç‰¹å¾

---

## äºŒã€StringIndexer æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¦ç”¨ï¼Ÿ

### æ„æ€ï¼š

æŠŠ **å­—ç¬¦ä¸²ç±»åˆ«**ï¼ˆæ¯”å¦‚ txn_typeï¼‰ â†’ **æ•°å­—ç´¢å¼•**ï¼ˆ0,1,2â€¦ï¼‰

* DEBIT â†’ 0
* CREDIT â†’ 1
* TRANSFER â†’ 2

### é“¶è¡Œä½œç”¨ï¼š

1. **æ¨¡å‹ä¸èƒ½ç›´æ¥ç†è§£æ–‡å­—**

   * Logistic / Linear / Tree éƒ½åªèƒ½ç”¨æ•°å­—
2. **å¯åš One-Hot / æ•°å€¼ç‰¹å¾**

   * ç´§æ¥ç€ OneHotEncoder
3. **handleInvalid="keep"**

   * é˜²ç”Ÿäº§æ•°æ®ä¸­å‡ºç°æ–°çš„ txn_type crash
   * ä¼šç»™æœªçŸ¥ç±»åˆ«ä¸€ä¸ª indexï¼Œè®©æ¨¡å‹ä¹Ÿèƒ½å­¦â€œæœªçŸ¥ç±»åˆ«â€ä¿¡å·ï¼ˆæœ‰æ—¶å¾ˆå¼ºï¼Œå°¤å…¶æ˜¯æ¬ºè¯ˆæ£€æµ‹ï¼‰

---

## ä¸‰ã€OneHotEncoder æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆè¦ç”¨ï¼Ÿ

### æ„æ€ï¼š

æŠŠæ•°å­—ç´¢å¼• â†’ **ç¨€ç–å‘é‡**ï¼ˆ0/1ï¼‰ï¼Œæ¯ä¸ªç±»åˆ«ä¸€åˆ—

ç¤ºä¾‹ï¼š

```
DEBIT    â†’ [1,0,0]
CREDIT   â†’ [0,1,0]
TRANSFER â†’ [0,0,1]
```

### é“¶è¡Œä½œç”¨ï¼š

1. **æ¶ˆé™¤é¡ºåºè¯¯å¯¼**

   * StringIndexer ç¼–å·åªæ˜¯é¡ºåºï¼Œä¸èƒ½å½“å¤§å°ç”¨
   * OHE æŠŠæ¯ä¸ªç±»åˆ«ç‹¬ç«‹å‡ºæ¥ï¼Œæ¨¡å‹ä¸ä¼šè¯¯è§£
2. **é€‚åˆçº¿æ€§æ¨¡å‹**

   * Logistic / Linear å›å½’è¦æ±‚ç‰¹å¾ç‹¬ç«‹
3. **ç¨€ç–å­˜å‚¨**

   * é«˜ç»´ç±»åˆ«ä¸ä¼šå ç”¨å¤ªå¤šå†…å­˜

âš ï¸ æ³¨æ„ï¼š

* æ ‘æ¨¡å‹ä¸éœ€è¦ OHEï¼Œç›´æ¥ç”¨ç´¢å¼•å°±å¯ä»¥
* dropLast=True é¿å…å¤šåˆ—å®Œå…¨å…±çº¿ï¼Œæ–¹ä¾¿çº¿æ€§æ¨¡å‹

---

## å››ã€Pipeline + StringIndexer + OneHotEncoder çš„å…·ä½“ä½œç”¨

ç»“åˆèµ·æ¥çœ‹ **å®Œæ•´æµç¨‹**ï¼š

1. **Pipeline**ï¼šæŠŠæ­¥éª¤ä¸²èµ·æ¥ï¼Œä¿è¯è®­ç»ƒ / æµ‹è¯• / ç”Ÿäº§ä¸€è‡´
2. **StringIndexer**ï¼šæŠŠç±»åˆ«è½¬æ•°å­—ï¼Œæ•°å­—æ˜¯ç´¢å¼•ï¼Œä¸æ˜¯æ•°å€¼å¤§å°
3. **OneHotEncoder**ï¼šæŠŠç´¢å¼•è½¬å‘é‡ï¼Œæ¯ä¸ªç±»åˆ«ç‹¬ç«‹åˆ—ï¼Œæ¶ˆé™¤é¡ºåºè¯¯å¯¼
4. **ç»“æœ**ï¼š

   * è®­ç»ƒé›†ã€æµ‹è¯•é›†ã€çº¿ä¸Šæ•°æ®ç»Ÿä¸€å¤„ç†
   * æ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨
   * å¯ä»¥å®‰å…¨åº”å¯¹æ–°ç±»åˆ«ï¼Œä¸æŒ‚æ‰

---

## äº”ã€ä¸¾ä¸ªé“¶è¡Œåœºæ™¯ä¾‹å­ï¼ˆMLE å®æˆ˜ï¼‰

| transaction_id | txn_type | txn_type_idx | txn_type_ohe |
| -------------- | -------- | ------------ | ------------ |
| TXN001         | DEBIT    | 0            | [1,0,0]      |
| TXN002         | CREDIT   | 1            | [0,1,0]      |
| TXN003         | REVERSAL | 2            | [0,0,1]      |

* **æ¨¡å‹ç”¨ txn_type_ohe** æ¥åˆ¤æ–­ä¸åŒäº¤æ˜“ç±»å‹å¯¹ **æ¬ºè¯ˆæ¦‚ç‡ / è¿çº¦æ¦‚ç‡** çš„å½±å“
* **å¦‚æœçº¿ä¸Šå‡ºç°æ–° txn_typeï¼ˆFEEï¼‰**

  * StringIndexer ä¼šåˆ†é…æ–°çš„ index
  * OneHotEncoder ä¼šç”Ÿæˆâ€œæœªçŸ¥ç±»åˆ«â€å‘é‡
  * æ¨¡å‹èƒ½å­¦åˆ°â€œæœªçŸ¥äº¤æ˜“ç±»å‹ä¹Ÿå¯èƒ½æœ‰é£é™©â€

---

âœ… æ€»ç»“ä¸€å¥è¯ï¼š

> Pipeline + StringIndexer + OneHotEncoder æ˜¯ **é“¶è¡Œæœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹çš„æ ‡å‡†åšæ³•**ï¼Œå¯ä»¥æŠŠç±»åˆ«ç‰¹å¾å®‰å…¨ã€é«˜æ•ˆã€è‡ªåŠ¨åŒ–åœ°è½¬æˆæ¨¡å‹å¯ç”¨çš„æ•°å€¼ç‰¹å¾ï¼ŒåŒæ—¶é˜²æ­¢ç”Ÿäº§æ•°æ®å¼‚å¸¸æˆ–æ–°ç±»åˆ«å¯¼è‡´æŠ¥é”™ã€‚

---
æ˜ç™½ï¼Œæˆ‘å¸®ä½ æŠŠå‰é¢è§£é‡Šçš„ **Pipeline + StringIndexer + OneHotEncoder çš„åŸç†å’Œä½œç”¨**ï¼Œç›´æ¥æ•´åˆåˆ° **å¸¦ Spark ä»£ç çš„çŸ¥è¯†æ€»ç»“**ï¼Œè®©ä½ ä¸€è¾¹çœ‹åŸç†ä¸€è¾¹èƒ½ç›´æ¥è·‘ã€‚

---

# é“¶è¡Œ MLE ç‰¹å¾å·¥ç¨‹ï¼šPipeline + StringIndexer + OneHotEncoder

## ä¸€ã€èƒŒæ™¯

* `txn_type` æ˜¯é“¶è¡Œäº¤æ˜“è¡¨ä¸­çš„ç±»åˆ«ç‰¹å¾ï¼ˆDEBIT / CREDIT / TRANSFER / REVERSALâ€¦ï¼‰
* **ç›®æ ‡**ï¼šæŠŠå®ƒè½¬æ¢ä¸º **æ¨¡å‹å¯ç”¨ç‰¹å¾**ï¼Œé€‚åˆçº¿æ€§æˆ–æ ‘æ¨¡å‹
* **åŸåˆ™**ï¼š

  1. é˜²ç”Ÿäº§ crash â†’ `handleInvalid="keep"`
  2. çº¿æ€§æ¨¡å‹ â†’ ç”¨ OHE æ¶ˆé™¤é¡ºåºè¯¯å¯¼
  3. æ ‘æ¨¡å‹ â†’ ç›´æ¥ç”¨ç´¢å¼•ä¹Ÿå¯

---

## äºŒã€Spark ä»£ç ç¤ºä¾‹

```python
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder
from pyspark.sql.functions import udf
from pyspark.sql.types import ArrayType, DoubleType

# 1ï¸âƒ£ åˆ›å»º Spark Session
spark = SparkSession.builder.appName("BankMLE").getOrCreate()

# 2ï¸âƒ£ å‡è®¾é“¶è¡Œ transactions è¡¨
data = [
    ("TXN001","DEBIT"),
    ("TXN002","CREDIT"),
    ("TXN003","TRANSFER"),
    ("TXN004","DEBIT"),
    ("TXN005","REVERSAL")
]
df = spark.createDataFrame(data, ["transaction_id", "txn_type"])
df.show()
```

è¾“å‡ºï¼š

```
+-------------+---------+
|transaction_id|txn_type|
+-------------+---------+
|TXN001       |DEBIT    |
|TXN002       |CREDIT   |
|TXN003       |TRANSFER |
|TXN004       |DEBIT    |
|TXN005       |REVERSAL |
+-------------+---------+
```

---

### 3ï¸âƒ£ å®šä¹‰ Pipeline

```python
# Step 1: StringIndexer
indexer = StringIndexer(
    inputCol="txn_type",
    outputCol="txn_type_idx",
    handleInvalid="keep"   # é˜²ç”Ÿäº§ crash
)

# Step 2: OneHotEncoder
encoder = OneHotEncoder(
    inputCols=["txn_type_idx"],
    outputCols=["txn_type_ohe"],
    dropLast=True           # é¿å… multicollinearity
)

# Step 3: Pipeline
pipeline = Pipeline(stages=[indexer, encoder])
```

---

### 4ï¸âƒ£ fit & transform

```python
# è®­ç»ƒ pipeline (åª fit åœ¨è®­ç»ƒé›†)
pipeline_model = pipeline.fit(df)
df_transformed = pipeline_model.transform(df)

df_transformed.select("transaction_id","txn_type","txn_type_idx","txn_type_ohe").show(truncate=False)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
+-------------+---------+------------+----------------+
|transaction_id|txn_type|txn_type_idx|txn_type_ohe    |
+-------------+---------+------------+----------------+
|TXN001       |DEBIT    |0.0         |(4,[0],[1.0])  |
|TXN002       |CREDIT   |1.0         |(4,[1],[1.0])  |
|TXN003       |TRANSFER |2.0         |(4,[2],[1.0])  |
|TXN004       |DEBIT    |0.0         |(4,[0],[1.0])  |
|TXN005       |REVERSAL |3.0         |(4,[3],[1.0])  |
+-------------+---------+------------+----------------+
```

---

### 5ï¸âƒ£ å±•å¼€ Sparse Vectorï¼ˆå¯é€‰ï¼Œä¾¿äºæŸ¥çœ‹ï¼‰

```python
# UDF: SparseVector -> Array
vector_to_array_udf = udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))
df_final = df_transformed.withColumn("txn_type_ohe_array", vector_to_array_udf("txn_type_ohe"))

df_final.select("transaction_id","txn_type","txn_type_ohe_array").show(truncate=False)
```

è¾“å‡ºï¼š

```
+-------------+---------+----------------+
|transaction_id|txn_type|txn_type_ohe_array|
+-------------+---------+----------------+
|TXN001       |DEBIT    |[1.0,0.0,0.0,0.0]|
|TXN002       |CREDIT   |[0.0,1.0,0.0,0.0]|
|TXN003       |TRANSFER |[0.0,0.0,1.0,0.0]|
|TXN004       |DEBIT    |[1.0,0.0,0.0,0.0]|
|TXN005       |REVERSAL |[0.0,0.0,0.0,1.0]|
+-------------+---------+----------------+
```

âœ… å¯ä»¥ç›´æ¥å–‚ç»™ Logistic Regression æˆ–å­˜åˆ° Feature Store

---

## ä¸‰ã€çŸ¥è¯†æ€»ç»“ï¼ˆç»“åˆä»£ç ï¼‰

| æ­¥éª¤            | ä½œç”¨                           | Spark ä»£ç                                                                                 |
| ------------- | ---------------------------- | --------------------------------------------------------------------------------------- |
| StringIndexer | å­—ç¬¦ä¸²ç±»åˆ« â†’ æ•°å­—ç´¢å¼•ï¼ˆ0,1,2â€¦ï¼‰         | `StringIndexer(inputCol="txn_type", outputCol="txn_type_idx", handleInvalid="keep")`    |
| OneHotEncoder | æ•°å­—ç´¢å¼• â†’ Sparse Vectorï¼ˆæ¯ç±»ç‹¬ç«‹ä¸€åˆ—ï¼‰ | `OneHotEncoder(inputCols=["txn_type_idx"], outputCols=["txn_type_ohe"], dropLast=True)` |
| Pipeline      | ä¸²è”æ­¥éª¤ï¼Œè®­ç»ƒ / æµ‹è¯• / çº¿ä¸Šä¸€è‡´          | `Pipeline(stages=[indexer, encoder])`                                                   |
| å±•ç¤º / debug    | æŸ¥çœ‹ OHE æ•°å€¼                    | `udf(lambda v: v.toArray().tolist())`                                                   |

---

### å››ã€é“¶è¡Œå®æˆ˜è¦ç‚¹

1. **handleInvalid="keep"** â†’ é˜²æ­¢ç”Ÿäº§ crash
2. **dropLast=True** â†’ é¿å…çº¿æ€§æ¨¡å‹å¤šé‡å…±çº¿
3. **è®­ç»ƒ Pipeline åª fit åœ¨è®­ç»ƒé›†** â†’ é˜²æ­¢æ•°æ®æ³„æ¼
4. **æ ‘æ¨¡å‹å¯åªç”¨ StringIndexer** â†’ é¿å…ç»´åº¦çˆ†ç‚¸
5. **Feature Store** â†’ å¯ä»¥å­˜ OHE åˆ—ç›´æ¥å¤ç”¨


å¥½ï¼Œè¿™ä¸ªæ˜¯ **Spark / é“¶è¡Œ MLE é¢è¯•å¿…é—®é¢˜**ã€‚
æˆ‘ç›´æ¥ç»™ä½  **ç»“è®º â†’ åŸç† â†’ é“¶è¡Œåœºæ™¯ â†’ é¢è¯•ç­”æ¡ˆ**ï¼Œä¸€éå°±æ‡‚ã€‚

---

## ä¸€å¥è¯ç»“è®ºï¼ˆå…ˆèƒŒï¼‰

> **StringIndexer = ç¼–ç ï¼ˆlabel â†’ numberï¼‰**
> **OneHotEncoder = å±•å¼€ï¼ˆnumber â†’ vectorï¼‰**
> ğŸ‘‰ **ä¸æ˜¯äºŒé€‰ä¸€ï¼Œæ˜¯å‰åä¸¤æ­¥**

---

## ä¸€ã€å®ƒä»¬å„è‡ªæ˜¯å¹²å˜›çš„ï¼Ÿ

### 1ï¸âƒ£ StringIndexerï¼ˆå¿…é¡»å…ˆç”¨ï¼‰

**ä½œç”¨ï¼š**

> æŠŠå­—ç¬¦ä¸²ç±»åˆ« â†’ æ•°å­— ID

```text
DEBIT    â†’ 0
CREDIT   â†’ 1
TRANSFER â†’ 2
```

```python
StringIndexer(
  inputCol="txn_type",
  outputCol="txn_type_idx"
)
```

ğŸ“Œ ç‰¹ç‚¹ï¼š

* ä¸æ˜¯ OHE
* æ•°å­— **æ²¡æœ‰å¤§å°æ„ä¹‰**
* æŒ‰ **é¢‘ç‡æ’åº**ï¼ˆé»˜è®¤ï¼‰

---

### 2ï¸âƒ£ OneHotEncoder

**ä½œç”¨ï¼š**

> æŠŠæ•°å­— ID â†’ One-Hot å‘é‡

```text
0 â†’ [1,0,0]
1 â†’ [0,1,0]
2 â†’ [0,0,1]
```

```python
OneHotEncoder(
  inputCols=["txn_type_idx"],
  outputCols=["txn_type_ohe"]
)
```

ğŸ“Œ ç‰¹ç‚¹ï¼š

* è¾“å‡ºæ˜¯ **Sparse Vector**
* é€‚åˆçº¿æ€§æ¨¡å‹
* é˜²æ­¢â€œè™šå‡é¡ºåºå…³ç³»â€

---

## äºŒã€ä¸ºä»€ä¹ˆä¸èƒ½åªç”¨ StringIndexerï¼Ÿï¼ˆå¾ˆå…³é”®ï¼‰

### âŒ é”™è¯¯ç†è§£

```text
CREDIT (2) > DEBIT (0)
```

æ¨¡å‹ä¼šä»¥ä¸ºï¼š

> CREDIT æ¯” DEBIT â€œæ›´å¤§â€

ğŸ‘‰ å¯¹ **Logistic / Linear Model** æ˜¯ç¾éš¾

---

## ä¸‰ã€é“¶è¡Œé‡Œä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ªï¼Ÿ

### åœºæ™¯ 1ï¼šLogistic Regression / Linear Model

âœ… **å¿…é¡»ï¼šStringIndexer + OneHotEncoder**

```text
txn_type_ohe = [0,1,0]
```

åŸå› ï¼š

* é¿å…é¡ºåºè¯¯å¯¼
* æƒé‡å¯è§£é‡Š

---

### åœºæ™¯ 2ï¼šTree / XGBoost / LightGBM

âœ… **åªç”¨ StringIndexer**

```text
txn_type_idx = 2
```

åŸå› ï¼š

* æ ‘ä¸å…³å¿ƒå¤§å°ï¼Œåªå…³å¿ƒ split
* OHE ä¼š **ç»´åº¦çˆ†ç‚¸**
* è®­ç»ƒæ›´æ…¢

---

### åœºæ™¯ 3ï¼šRule / SQL / Feature Engineering

âŒ éƒ½ä¸ç”¨
ç›´æ¥ï¼š

```sql
count(case when txn_type='DEBIT' then 1 end)
```

---

## å››ã€å¯¹æ¯”è¡¨ï¼ˆé¢è¯•æœ€çˆ±ï¼‰

| å¯¹æ¯”é¡¹     | StringIndexer | OneHotEncoder |
| ------- | ------------- | ------------- |
| è¾“å…¥      | String        | Index         |
| è¾“å‡º      | æ•°å­—            | å‘é‡            |
| æ˜¯å¦å•ç‹¬ç”¨   | âœ…ï¼ˆæ ‘æ¨¡å‹ï¼‰        | âŒ             |
| æ˜¯å¦æœ‰é¡ºåºè¯¯å¯¼ | âš ï¸ æœ‰          | âŒ             |
| ç»´åº¦      | 1             | N             |
| é“¶è¡Œä½¿ç”¨é¢‘ç‡  | â­ï¸â­ï¸â­ï¸        | â­ï¸â­ï¸          |

---

## äº”ã€çœŸå®é“¶è¡Œ Pipelineï¼ˆæ ‡å‡†å†™æ³•ï¼‰

```python
from pyspark.ml import Pipeline

pipeline = Pipeline(stages=[
    StringIndexer(
        inputCol="txn_type",
        outputCol="txn_type_idx",
        handleInvalid="keep"
    ),
    OneHotEncoder(
        inputCols=["txn_type_idx"],
        outputCols=["txn_type_ohe"],
        dropLast=True
    )
])
```

---

## å…­ã€é¢è¯•çº§æ€»ç»“å›ç­”ï¼ˆä½ å¯ä»¥ç›´æ¥èƒŒï¼‰

> StringIndexer converts categorical strings into numerical indices, which is required before modeling.
> OneHotEncoder then converts those indices into sparse vectors to remove any artificial ordinal relationship.
> In banking, we typically use both for linear models, but only StringIndexer for tree-based models to avoid dimensional explosion.

---

## ä¸ƒã€åŠ åˆ†ç‚¹ï¼ˆä½ åƒ CIBC / HSBC MLEï¼‰

* `handleInvalid="keep"` é˜² production crash
* `dropLast=True` é˜² multicollinearity
* Indexer **åª fit åœ¨ training data**ï¼ˆé˜² leakageï¼‰
* Feature Store é‡Œ **å­˜ OHE ç»“æœï¼Œä¸å­˜ raw**


